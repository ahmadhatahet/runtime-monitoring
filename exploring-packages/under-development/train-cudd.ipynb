{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7f5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff685c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env variables\n",
    "REPO_PATH = '/home/ah19/runtime-monitoring'\n",
    "DATASET = 'MNIST'\n",
    "PREFIX = 'Adam-256-30'\n",
    "FILENAME_POSTFIX = f'{DATASET}_{PREFIX}'\n",
    "DATA_FALVOR = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4189f-fe71-44aa-b95b-c3b385d2707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n",
    "from utilities.utils import load_json\n",
    "from utilities.pathManager import fetchPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f97ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base = Path(REPO_PATH)\n",
    "paths = fetchPaths(base, DATASET)\n",
    "\n",
    "path = paths[DATASET.lower()]\n",
    "path_bdd = paths['bdd_' + DATA_FALVOR] / FILENAME_POSTFIX\n",
    "\n",
    "path_lastHiddenLayer_pca = paths['lastHiddenLayer_pca']\n",
    "path_lastHiddenLayer_pca_single = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Single'\n",
    "# path_lastHiddenLayer_pca_classes = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Classes'\n",
    "\n",
    "path_lastHiddenLayer = paths['lastHiddenLayer_' + DATA_FALVOR] / FILENAME_POSTFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae325d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train Data ...\n",
      "Loading test Data ...\n",
      "Loading Neurons ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import Data\n",
    "print('Loading train Data ...')\n",
    "df = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_train.csv')\n",
    "\n",
    "# split train data\n",
    "df_true = df[df['true'] == True].copy()\n",
    "df_true = df_true.drop('true', axis=1).reset_index(drop=True)\n",
    "\n",
    "print('Loading test Data ...')\n",
    "df_test = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_test.csv')\n",
    "\n",
    "\n",
    "print('Loading Neurons ...')\n",
    "neurons = load_json(path_lastHiddenLayer_pca_single / f'{FILENAME_POSTFIX}_neurons.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df61088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dd.cudd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-53141fdb1f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dd.cudd'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import asizeof\n",
    "import time\n",
    "\n",
    "from dd.cudd import BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MonitorBDD:\n",
    "    def __init__(self, num_neurons, thld_1, thld_2=None, thld_3=None, neurons=None, verbose=False):\n",
    "\n",
    "        self.bdd = BDD()\n",
    "        self.roots = self.bdd.false\n",
    "        self.num_neurons = num_neurons\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.thld_1 = thld_1\n",
    "        self.thld_2 = thld_2\n",
    "        self.thld_3 = thld_3\n",
    "        self.num_bits = 2 if thld_2 is not None or thld_3 is not None else 1\n",
    "        self.num_vars = num_neurons * self.num_bits\n",
    "\n",
    "        self.neurons = neurons\n",
    "        if self.neurons is not None:\n",
    "            self.neurons = np.array([int(n[1:]) for n in neurons])\n",
    "            self.thld_1 = thld_1[self.neurons]\n",
    "            self.thld_2 = thld_2[self.neurons] if self.thld_2 is not None else None\n",
    "            self.thld_3 = thld_3[self.neurons] if self.thld_3 is not None else None\n",
    "\n",
    "        self.vars, self.vars_not = self.__declare_vars()\n",
    "\n",
    "        self.stats = pd.DataFrame({\n",
    "            'thld': [],\n",
    "            'df': [],\n",
    "            'build_time': [],\n",
    "            'size_before_reorder_mb': [],\n",
    "            'reorder_time': [],\n",
    "            'size_after_reorder_mb': []\n",
    "        })\n",
    "\n",
    "\n",
    "    def __declare_vars(self):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # generate vars either x0_0 or x0_0 and x0_1 per neuron\n",
    "        vars_range = self.neurons if self.neurons is not None else range(self.num_neurons)\n",
    "        v = [f'x{n}_{i}' for i in range(self.num_bits) for n in vars_range]\n",
    "\n",
    "        # add vars to bdd\n",
    "        [ *map(self.bdd.add_var, v) ]\n",
    "\n",
    "        # generate negative vars\n",
    "        vars = np.array([ *map(self.bdd.var, v) ])\n",
    "        vars_not = np.array([ ~v for v in vars ])\n",
    "\n",
    "        return vars, vars_not\n",
    "\n",
    "\n",
    "    def __multi_thlds(self, x):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        x = x.reshape(x.shape[0], 1)\n",
    "        x = np.where(x == [0], [0, 0], # 0\n",
    "             np.where(x == [1], [1, 0], # 1\n",
    "             np.where(x == [2], [0, 1], # 2\n",
    "             [1, 1] ) ) )# 3\n",
    "        return np.reshape(x, x.shape[0] * 2)\n",
    "\n",
    "\n",
    "    def __applying_thlds(self, df):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_thld = (df >=  self.thld_1).astype('int8')\n",
    "\n",
    "        if self.thld_2 is not None:\n",
    "            df_thld += (df >=  self.thld_2).astype('int8')\n",
    "\n",
    "        if self.thld_3 is not None:\n",
    "            df_thld += (df >=  self.thld_3).astype('int8')\n",
    "\n",
    "        return df_thld.to_numpy()\n",
    "\n",
    "\n",
    "    def check_pattern_length(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if self.num_bits == 2:\n",
    "            assert len(self.vars)/2 == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "        else:\n",
    "            assert len(self.vars) == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "\n",
    "\n",
    "    def construct_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # replace 1 with vars and 0 with vars_not\n",
    "        expr = np.where( row == 1, self.vars, self.vars_not )\n",
    "        return np.bitwise_and.reduce( expr )\n",
    "\n",
    "\n",
    "    def __add_patterns(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        or_expressions = np.apply_along_axis(self.construct_pattern, 1, row)\n",
    "        self.roots |= np.bitwise_or.reduce( or_expressions )\n",
    "\n",
    "\n",
    "    def flip_bit(self, patterns, eta):\n",
    "        \"\"\"flip n-th bit to allow more freedom(false positive)\n",
    "           if et = 0 then pattern as is\n",
    "           if et = 1 then loop over each bit and force it to one\n",
    "           et = 2 loop over 2 bits and flip them ... etc\n",
    "           drop any duplicate patterns\"\"\"\n",
    "\n",
    "        for nth in range(patterns.shape[1]-eta+1):\n",
    "            temp = patterns.copy()\n",
    "            temp[:, nth:nth+eta] = 1\n",
    "            temp = np.unique(temp, axis=0)\n",
    "            yield temp\n",
    "\n",
    "\n",
    "    def add_dataframe(self, df, eta=0, eval_dfs=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        if self.neurons is not None:\n",
    "            df = df[df.columns[self.neurons]].drop_duplicates()\n",
    "        else:\n",
    "            df = df[df.columns[:self.num_neurons]].drop_duplicates()\n",
    "\n",
    "        patterns = self.__applying_thlds(df)\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "\n",
    "#         np.apply_along_axis(self.__add_one_pattern, 1, patterns)\n",
    "        \n",
    "        self.__add_patterns(patterns)\n",
    "\n",
    "#         for i in range(df.shape[0]):\n",
    "#             self.__add_one_pattern(patterns[i])\n",
    "        \n",
    "        \n",
    "        build_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "\n",
    "        row = self.stats.shape[0]+1\n",
    "        self.stats.loc[row, 'df'] = 0\n",
    "        self.stats.loc[row, 'build_time'] = build_time\n",
    "        self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        BDD.reorder(self.bdd)\n",
    "        bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "        self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "        self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "        # add column for scoring\n",
    "        if eval_dfs is not None:\n",
    "            for eval_df in eval_dfs:\n",
    "                self.evaluate_dataframe(eval_df, 0)\n",
    "\n",
    "        # flip bit\n",
    "        if eta > 0:\n",
    "            # evaluate starting from 1 degree of freedom\n",
    "            for et in range(1, eta+1):\n",
    "                row = self.stats.shape[0]+1\n",
    "                start = time.perf_counter()\n",
    "\n",
    "                # flip each neuron to 1 then add to BDD\n",
    "                for flipped_patterns in self.flip_bit(patterns, et):\n",
    "                    \n",
    "                    self.__add_patterns(flipped_patterns)\n",
    "                    \n",
    "\n",
    "                build_time = round(time.perf_counter() - start, 3)\n",
    "                self.stats.loc[row, 'df'] = et\n",
    "                self.stats.loc[row, 'build_time'] = build_time\n",
    "                self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # reorder\n",
    "                start = time.perf_counter()\n",
    "                BDD.reorder(self.bdd)\n",
    "                bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "                self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "                self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # add column for scoring\n",
    "                if eval_dfs is not None:\n",
    "                    for eval_df in eval_dfs:\n",
    "                        self.evaluate_dataframe(eval_df, et)\n",
    "\n",
    "        # return evaluated dataframes\n",
    "        if eval_dfs is not None:\n",
    "            return eval_dfs\n",
    "\n",
    "        self.stats = self.stats.loc[self.stats['df'] == eta]\n",
    "        return\n",
    "\n",
    "\n",
    "    def check_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if (self.roots & self.construct_pattern(row) ) == self.bdd.false:\n",
    "            return 0 # means not found\n",
    "        else:\n",
    "            return 1 # found it\n",
    "\n",
    "\n",
    "    def evaluate_dataframe(self, df, eta=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        bdd_results = np.zeros(df.shape[0], dtype=np.int8)\n",
    "\n",
    "        if self.neurons is not None:\n",
    "            patterns = self.__applying_thlds(df[df.columns[self.neurons]])\n",
    "        else:\n",
    "            patterns = self.__applying_thlds(df[df.columns[:self.num_neurons]])\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "        bdd_results = np.apply_along_axis(self.check_one_pattern, 1, patterns)\n",
    "\n",
    "        if eta is not None:\n",
    "            df[f'bdd_{eta}'] = bdd_results\n",
    "            return\n",
    "\n",
    "        # if the function called specifically, return scored df after evaluating\n",
    "        df['bdd'] = bdd_results\n",
    "\n",
    "        return self.score_dataframe(df)\n",
    "\n",
    "\n",
    "    def score_dataframe(self, df, bdd_col='bdd'):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_all_classes = df[['y', 'true']].groupby('y').count().sort_index()\n",
    "        df_all_classes.columns = ['count']\n",
    "\n",
    "        df_out_of_pattern_images = df.loc[df[bdd_col] == 0, ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_images.columns = [bdd_col + '_false']\n",
    "\n",
    "        df_out_of_pattern_misclassified_images = df.loc[(df[bdd_col] == 0) & (df['true'] == False), ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_misclassified_images.columns = [bdd_col + '_false_miss_classified']\n",
    "\n",
    "        df_scores = df_all_classes.join(df_out_of_pattern_images).join(df_out_of_pattern_misclassified_images)\n",
    "\n",
    "        del df_out_of_pattern_images, df_out_of_pattern_misclassified_images\n",
    "\n",
    "        total_images = df_all_classes['count'].sum()\n",
    "        out_of_pattern_images = (df[bdd_col] == 0).sum()\n",
    "        out_of_pattern_misclassified_images = ((df['true'] == False) & (df[bdd_col] == 0)).sum()\n",
    "        df_scores.loc['all', :] = [total_images, out_of_pattern_images, out_of_pattern_misclassified_images]\n",
    "\n",
    "        # if data frame return 0 rows, a nan will be placed\n",
    "        df_scores.fillna(0, inplace=True)\n",
    "\n",
    "        # calculate metrics\n",
    "        df_scores['outOfPattern'] = df_scores[bdd_col + '_false'] / df_scores['count']\n",
    "        df_scores['outOfPatternMissClassified'] = df_scores[bdd_col + '_false_miss_classified'] / df_scores[bdd_col + '_false']\n",
    "\n",
    "        # add mean of all classes\n",
    "        a1 = df_scores.loc[df_scores.index != 'all', 'outOfPattern'].mean()\n",
    "        a2 = df_scores.loc[df_scores.index != 'all', 'outOfPatternMissClassified'].mean()\n",
    "        df_scores.loc['all_mean', :] = [0, 0, total_images, a1, a2]\n",
    "\n",
    "        # if class is never missclassified and bdd recognize all of his patterns\n",
    "        # both outOfPattern and outOfPatternMissClassified will be 0\n",
    "        # so the division will result in NaN\n",
    "        df_scores['outOfPatternMissClassified'].replace({np.nan:0.0, 0.0:1.0}, inplace=True)\n",
    "        df_scores['outOfPattern'].replace({np.nan:0.0}, inplace=True)\n",
    "\n",
    "        # no missclassification for a class\n",
    "        df_scores[bdd_col + '_false'].replace({np.nan:0.0}, inplace=True)\n",
    "        df_scores[bdd_col + '_false_miss_classified'].replace({np.nan:0.0}, inplace=True)\n",
    "\n",
    "        if bdd_col=='bdd':\n",
    "            return df_scores.reset_index()\n",
    "        return df_scores\n",
    "\n",
    "\n",
    "    def score_dataframe_multi_eta(self, df, eta):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_scores = pd.DataFrame()\n",
    "\n",
    "        for et in range(eta+1):\n",
    "            temp = self.score_dataframe(df, f'bdd_{et}')\n",
    "            temp['eta'] = et\n",
    "            temp.columns = [*map(lambda x: x.replace(f'bdd_{et}', ''), temp.columns)]\n",
    "            df_scores = pd.concat([df_scores, temp])\n",
    "            del temp\n",
    "\n",
    "        return df_scores.reset_index()\n",
    "\n",
    "\n",
    "    def plot_stats(self, df, stage, true=True, save_folder=None, prefix=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df = df.loc[df['true'] == true].set_index('y')\n",
    "        mean_ = df['outOfPattern'].mean().round(3)\n",
    "\n",
    "        neurons = f' Number of neuron: {len(self.neurons)}' if self.neurons is not None else None\n",
    "        title = f'{stage} - {true} - #out of pattern: {mean_}{neurons}\\n'\n",
    "        filename = f'{stage.lower()}_{true}_outOfPattern'\n",
    "        color = 'teal' if true else 'orange'\n",
    "\n",
    "        df['outOfPattern'].plot(\n",
    "            kind='bar', title=title, legend=False, color=color, xlabel='', hatch='x', edgecolor='black')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.axhline(mean_, color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "\n",
    "        if save_folder is not None:\n",
    "            plt.savefig(save_folder / f'bdd_scores_{filename}_{prefix}.jpg', dpi=150, transparent=False)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define threshold\n",
    "\n",
    "p = 0.5\n",
    "\n",
    "thld = np.quantile(df_true.drop('y', axis=1), p, axis=0)\n",
    "thld_name = f'qth_{p}'\n",
    "\n",
    "# degree of freedom\n",
    "eta = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36fce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons )\n",
    "df_2, df_test_2 = patterns.add_dataframe( df_true, eta, eval_dfs=[df.copy(), df_test.copy()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b15617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thld</th>\n",
       "      <th>df</th>\n",
       "      <th>build_time</th>\n",
       "      <th>size_before_reorder_mb</th>\n",
       "      <th>reorder_time</th>\n",
       "      <th>size_after_reorder_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.598</td>\n",
       "      <td>367.696</td>\n",
       "      <td>18.072</td>\n",
       "      <td>64.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.927</td>\n",
       "      <td>2496.796</td>\n",
       "      <td>73.794</td>\n",
       "      <td>508.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>156.923</td>\n",
       "      <td>2642.926</td>\n",
       "      <td>84.283</td>\n",
       "      <td>677.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thld   df  build_time  size_before_reorder_mb  reorder_time  \\\n",
       "1   NaN  0.0      29.598                 367.696        18.072   \n",
       "2   NaN  1.0     169.927                2496.796        73.794   \n",
       "3   NaN  2.0     156.923                2642.926        84.283   \n",
       "\n",
       "   size_after_reorder_mb  \n",
       "1                 64.660  \n",
       "2                508.566  \n",
       "3                677.106  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a754cf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>count</th>\n",
       "      <th>_false</th>\n",
       "      <th>_false_miss_classified</th>\n",
       "      <th>outOfPattern</th>\n",
       "      <th>outOfPatternMissClassified</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.101020</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.119824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.194767</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087129</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>982.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.071283</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>892.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.080717</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>958.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.063674</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.214008</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>974.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.148871</td>\n",
       "      <td>0.075862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.125374</td>\n",
       "      <td>0.056414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>982.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>892.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>958.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.044747</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>974.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>all</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.100346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>all_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.099261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034361</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>982.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>892.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>958.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>974.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>all</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.108787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>all_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.103733</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y    count  _false  _false_miss_classified  outOfPattern  \\\n",
       "0          0    980.0    99.0                     3.0      0.101020   \n",
       "1          1   1135.0   136.0                     4.0      0.119824   \n",
       "2          2   1032.0   201.0                     4.0      0.194767   \n",
       "3          3   1010.0    88.0                     1.0      0.087129   \n",
       "4          4    982.0    70.0                     3.0      0.071283   \n",
       "5          5    892.0    72.0                     8.0      0.080717   \n",
       "6          6    958.0    61.0                     7.0      0.063674   \n",
       "7          7   1028.0   220.0                     3.0      0.214008   \n",
       "8          8    974.0   145.0                    11.0      0.148871   \n",
       "9          9   1009.0   174.0                    20.0      0.172448   \n",
       "10       all  10000.0  1266.0                    64.0      0.126600   \n",
       "11  all_mean      0.0     0.0                 10000.0      0.125374   \n",
       "12         0    980.0    14.0                     0.0      0.014286   \n",
       "13         1   1135.0    47.0                     3.0      0.041410   \n",
       "14         2   1032.0    52.0                     1.0      0.050388   \n",
       "15         3   1010.0    17.0                     0.0      0.016832   \n",
       "16         4    982.0    14.0                     2.0      0.014257   \n",
       "17         5    892.0    11.0                     1.0      0.012332   \n",
       "18         6    958.0    17.0                     4.0      0.017745   \n",
       "19         7   1028.0    46.0                     2.0      0.044747   \n",
       "20         8    974.0    28.0                     2.0      0.028747   \n",
       "21         9   1009.0    43.0                    14.0      0.042616   \n",
       "22       all  10000.0   289.0                    29.0      0.028900   \n",
       "23  all_mean      0.0     0.0                 10000.0      0.028336   \n",
       "24         0    980.0    11.0                     0.0      0.011224   \n",
       "25         1   1135.0    39.0                     3.0      0.034361   \n",
       "26         2   1032.0    42.0                     1.0      0.040698   \n",
       "27         3   1010.0    14.0                     0.0      0.013861   \n",
       "28         4    982.0    11.0                     0.0      0.011202   \n",
       "29         5    892.0    11.0                     1.0      0.012332   \n",
       "30         6    958.0    12.0                     4.0      0.012526   \n",
       "31         7   1028.0    40.0                     2.0      0.038911   \n",
       "32         8    974.0    25.0                     2.0      0.025667   \n",
       "33         9   1009.0    34.0                    13.0      0.033697   \n",
       "34       all  10000.0   239.0                    26.0      0.023900   \n",
       "35  all_mean      0.0     0.0                 10000.0      0.023448   \n",
       "\n",
       "    outOfPatternMissClassified  eta  \n",
       "0                     0.030303    0  \n",
       "1                     0.029412    0  \n",
       "2                     0.019900    0  \n",
       "3                     0.011364    0  \n",
       "4                     0.042857    0  \n",
       "5                     0.111111    0  \n",
       "6                     0.114754    0  \n",
       "7                     0.013636    0  \n",
       "8                     0.075862    0  \n",
       "9                     0.114943    0  \n",
       "10                    0.050553    0  \n",
       "11                    0.056414    0  \n",
       "12                    1.000000    1  \n",
       "13                    0.063830    1  \n",
       "14                    0.019231    1  \n",
       "15                    1.000000    1  \n",
       "16                    0.142857    1  \n",
       "17                    0.090909    1  \n",
       "18                    0.235294    1  \n",
       "19                    0.043478    1  \n",
       "20                    0.071429    1  \n",
       "21                    0.325581    1  \n",
       "22                    0.100346    1  \n",
       "23                    0.099261    1  \n",
       "24                    1.000000    2  \n",
       "25                    0.076923    2  \n",
       "26                    0.023810    2  \n",
       "27                    1.000000    2  \n",
       "28                    1.000000    2  \n",
       "29                    0.090909    2  \n",
       "30                    0.333333    2  \n",
       "31                    0.050000    2  \n",
       "32                    0.080000    2  \n",
       "33                    0.382353    2  \n",
       "34                    0.108787    2  \n",
       "35                    0.103733    2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = patterns.score_dataframe_multi_eta(df_test_2, eta)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38806418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f127275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
