{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d7f5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff685c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env variables\n",
    "REPO_PATH = '/home/ah19/runtime-monitoring'\n",
    "DATASET = 'MNIST'\n",
    "PREFIX = 'Elastic32'\n",
    "FILENAME_POSTFIX = f'{DATASET}_{PREFIX}'\n",
    "DATA_FALVOR = 'raw'\n",
    "LOAD_NEURONS = True\n",
    "POSTFIX = 'SeperateETA'\n",
    "\n",
    "import os\n",
    "os.chdir('../..')\n",
    "from utilities.utils import load_json\n",
    "from utilities.pathManager import fetchPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f97ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base = Path(REPO_PATH)\n",
    "paths = fetchPaths(base, DATASET)\n",
    "\n",
    "path = paths[DATASET.lower()]\n",
    "path_bdd_testingThresholds_raw = paths['bdd_testingThresholds_raw'] / FILENAME_POSTFIX\n",
    "\n",
    "\n",
    "# path_lastHiddenLayer = paths['lastHiddenLayer']\n",
    "# path_lastHiddenLayer_raw = paths['lastHiddenLayer_raw']\n",
    "path_lastHiddenLayer_pca = paths['lastHiddenLayer_pca']\n",
    "path_lastHiddenLayer_pca_single = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Single'\n",
    "# path_lastHiddenLayer_pca_classes = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Classes'\n",
    "\n",
    "path_lastHiddenLayer = paths['lastHiddenLayer_raw'] / FILENAME_POSTFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae325d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train Data ...\n",
      "Loading test Data ...\n",
      "Loading Neurons ...\n"
     ]
    }
   ],
   "source": [
    "# import Data\n",
    "print('Loading train Data ...')\n",
    "df = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_train.csv')\n",
    "\n",
    "# split train data\n",
    "df_true = df[df['true'] == True].copy()\n",
    "df_true = df_true.drop('true', axis=1).reset_index(drop=True)\n",
    "\n",
    "print('Loading test Data ...')\n",
    "df_test = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_test.csv')\n",
    "\n",
    "\n",
    "print('Loading Neurons ...')\n",
    "neurons = None\n",
    "if LOAD_NEURONS:\n",
    "    neurons = load_json(path_lastHiddenLayer_pca_single / f'{FILENAME_POSTFIX}_neurons.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "094071ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pyeda.inter import *\n",
    "from pyeda.boolalg.bdd import BDDZERO, BDDONE\n",
    "from pympler import asizeof\n",
    "import time\n",
    "\n",
    "class MonitorBDD:\n",
    "    def __init__(self, num_neurons, thld_1, thld_2=None, thld_3=None, neurons=None, verbose=False):\n",
    "\n",
    "        self.bdd = BDD()\n",
    "        self.roots = self.bdd.false\n",
    "        self.num_neurons = num_neurons\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.thld_1 = thld_1\n",
    "        self.thld_2 = thld_2\n",
    "        self.thld_3 = thld_3\n",
    "        self.num_bits = 2 if thld_2 is not None or thld_3 is not None else 1\n",
    "        self.num_vars = num_neurons * self.num_bits\n",
    "\n",
    "        self.neurons = neurons\n",
    "        if self.neurons is not None:\n",
    "            self.neurons = np.array([int(n[1:]) for n in neurons])\n",
    "            self.thld_1 = thld_1[self.neurons]\n",
    "            self.thld_2 = thld_2[self.neurons] if self.thld_2 is not None else None\n",
    "            self.thld_3 = thld_3[self.neurons] if self.thld_3 is not None else None\n",
    "\n",
    "        self.vars, self.vars_not = self.__declare_vars()\n",
    "\n",
    "        self.stats = pd.DataFrame({\n",
    "            'thld': [],\n",
    "            'df': [],\n",
    "            'build_time': [],\n",
    "            'size_before_reorder_mb': [],\n",
    "            'reorder_time': [],\n",
    "            'size_after_reorder_mb': []\n",
    "        })\n",
    "\n",
    "\n",
    "    def __declare_vars(self):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # generate vars either x0_0 or x0_0 and x0_1 per neuron\n",
    "        vars_range = self.neurons if self.neurons is not None else range(self.num_neurons)\n",
    "        v = [f'x{n}_{i}' for i in range(self.num_bits) for n in vars_range]\n",
    "\n",
    "        # add vars to bdd\n",
    "        [ *map(self.bdd.add_var, v) ]\n",
    "\n",
    "        # generate negative vars\n",
    "        vars = np.array([ *map(self.bdd.var, v) ])\n",
    "        vars_not = np.array([ ~v for v in vars ])\n",
    "\n",
    "        return vars, vars_not\n",
    "\n",
    "\n",
    "    def __multi_thlds(self, x):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        x = x.reshape(x.shape[0], 1)\n",
    "        x = np.where(x == [0], [0, 0], # 0\n",
    "             np.where(x == [1], [1, 0], # 1\n",
    "             np.where(x == [2], [0, 1], # 2\n",
    "             [1, 1] ) ) )# 3\n",
    "        return np.reshape(x, x.shape[0] * 2)\n",
    "\n",
    "\n",
    "    def __applying_thlds(self, df):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_thld = (df >=  self.thld_1).astype('int8')\n",
    "\n",
    "        if self.thld_2 is not None:\n",
    "            df_thld += (df >=  self.thld_2).astype('int8')\n",
    "\n",
    "        if self.thld_3 is not None:\n",
    "            df_thld += (df >=  self.thld_3).astype('int8')\n",
    "\n",
    "        return df_thld.to_numpy()\n",
    "\n",
    "\n",
    "    def check_pattern_length(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if self.num_bits == 2:\n",
    "            assert len(self.vars)/2 == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "        else:\n",
    "            assert len(self.vars) == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "\n",
    "\n",
    "    def construct_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # replace 1 with vars and 0 with vars_not\n",
    "        expr = np.where( row == 1, self.vars, self.vars_not )\n",
    "        return np.bitwise_and.reduce( expr )\n",
    "\n",
    "\n",
    "    def __add_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        self.roots |= self.construct_pattern(row)\n",
    "\n",
    "\n",
    "    def flip_bit(self, patterns, eta):\n",
    "        \"\"\"flip n-th bit to allow more freedom(false positive)\n",
    "           if et = 0 then pattern as is\n",
    "           if et = 1 then loop over each bit and force it to one\n",
    "           et = 2 loop over 2 bits and flip them ... etc\n",
    "           drop any duplicate patterns\"\"\"\n",
    "\n",
    "        for nth in range(patterns.shape[1]-eta+1):\n",
    "            temp = patterns.copy()\n",
    "            temp[:, nth:nth+eta] = 1\n",
    "            temp = np.unique(temp, axis=0)\n",
    "            yield temp\n",
    "\n",
    "\n",
    "    def add_dataframe(self, df, eta=0, eval_dfs=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        if self.neurons is not None:\n",
    "            df = df[df.columns[self.neurons]].drop_duplicates()\n",
    "        else:\n",
    "            df = df[df.columns[:self.num_neurons]].drop_duplicates()\n",
    "\n",
    "        patterns = self.__applying_thlds(df)\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            self.__add_one_pattern(patterns[i])\n",
    "        build_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "\n",
    "        row = self.stats.shape[0]+1\n",
    "        self.stats.loc[row, 'df'] = 0\n",
    "        self.stats.loc[row, 'build_time'] = build_time\n",
    "        self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "        # add column for scoring\n",
    "        if eval_dfs is not None:\n",
    "            for eval_df in eval_dfs:\n",
    "                self.evaluate_dataframe(eval_df, 0)\n",
    "\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        BDD.reorder(self.bdd)\n",
    "        bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "        self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "        self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "\n",
    "        # flip bit\n",
    "        if eta > 0:\n",
    "            # evaluate starting from 1 degree of freedom\n",
    "            for et in range(1, eta+1):\n",
    "                row = self.stats.shape[0]+1\n",
    "                start = time.perf_counter()\n",
    "\n",
    "                # flip each neuron to 1 then add to BDD\n",
    "                for flipped_patterns in self.flip_bit(patterns, et):\n",
    "                    for i in range(flipped_patterns.shape[0]):\n",
    "                        self.__add_one_pattern(flipped_patterns[i])\n",
    "                    # end loop flipped_patterns\n",
    "\n",
    "                build_time = round(time.perf_counter() - start, 3)\n",
    "                self.stats.loc[row, 'df'] = et\n",
    "                self.stats.loc[row, 'build_time'] = build_time\n",
    "                self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # reorder\n",
    "                start = time.perf_counter()\n",
    "                BDD.reorder(self.bdd)\n",
    "                bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "                self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "                self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # add column for scoring\n",
    "                if eval_dfs is not None:\n",
    "                    for eval_df in eval_dfs:\n",
    "                        self.evaluate_dataframe(eval_df, et)\n",
    "\n",
    "        # return evaluated dataframes\n",
    "        if eval_dfs is not None:\n",
    "            return eval_dfs\n",
    "\n",
    "        self.stats = self.stats.loc[self.stats['df'] == eta]\n",
    "        return\n",
    "\n",
    "\n",
    "    def check_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if (self.roots & self.construct_pattern(row) ) == self.bdd.false:\n",
    "            return 0 # means not found\n",
    "        else:\n",
    "            return 1 # found it\n",
    "\n",
    "\n",
    "    def evaluate_dataframe(self, df, eta=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        bdd_results = np.zeros(df.shape[0], dtype=np.int8)\n",
    "\n",
    "        if self.neurons is not None:\n",
    "            patterns = self.__applying_thlds(df[df.columns[self.neurons]])\n",
    "        else:\n",
    "            patterns = self.__applying_thlds(df[df.columns[:self.num_neurons]])\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            bdd_results[i] = self.check_one_pattern(patterns[i])\n",
    "\n",
    "        if eta is not None:\n",
    "            df[f'bdd_{eta}'] = bdd_results\n",
    "            return\n",
    "\n",
    "        # if the function called specifically, return scored df after evaluating\n",
    "        df['bdd'] = bdd_results\n",
    "\n",
    "        return self.score_dataframe(df)\n",
    "\n",
    "\n",
    "    def score_dataframe(self, df, bdd_col='bdd'):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_out_of_pattern_images = df.loc[df[bdd_col] == 0, ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_images.columns = [bdd_col + '_false']\n",
    "\n",
    "        df_out_of_pattern_misclassified_images = df.loc[(df[bdd_col] == 0) & (df['true'] == False), ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_misclassified_images.columns = [bdd_col + '_false_miss_classified']\n",
    "\n",
    "        df_scores = df_out_of_pattern_images.join(df_out_of_pattern_misclassified_images).join(df['y'].value_counts())\n",
    "        df_scores.rename({'y': 'count'}, axis=1, inplace=True)\n",
    "\n",
    "        del df_out_of_pattern_images, df_out_of_pattern_misclassified_images\n",
    "\n",
    "        total_images = df.shape[0]\n",
    "        out_of_pattern_images = (df[bdd_col] == 0).sum()\n",
    "        out_of_pattern_misclassified_images = ((df['true'] == False) & (df[bdd_col] == 0)).sum()\n",
    "        df_scores.loc['all', :] = [out_of_pattern_images, out_of_pattern_misclassified_images, total_images]\n",
    "        # if data frame return 0 rows, a nan will be placed\n",
    "        df_scores.fillna(0, inplace=True)\n",
    "        # calculate metrics\n",
    "        df_scores['outOfPattern'] = df_scores[bdd_col + '_false'] / df_scores['count']\n",
    "        df_scores['outOfPatternMissClassified'] = df_scores[bdd_col + '_false_miss_classified'] / df_scores[bdd_col + '_false']\n",
    "        # if class is never missclassified and bdd recognize all of his patterns\n",
    "        # both outOfPattern and outOfPatternMissClassified will be 0\n",
    "        # so the division will result in NaN\n",
    "        df_scores['outOfPatternMissClassified'].replace({np.nan:1.0, 0.0: 1.0}, inplace=True)\n",
    "        df_scores['outOfPattern'].replace({np.nan:0.0}, inplace=True)\n",
    "        # no missclassification for a class\n",
    "        df_scores[bdd_col + '_false'].replace({np.nan:0.0}, inplace=True)\n",
    "        df_scores[bdd_col + '_false_miss_classified'].replace({np.nan:0.0}, inplace=True)\n",
    "        # add mean of all classes\n",
    "        a1 = df_scores.loc[df_scores.index != 'all', 'outOfPattern'].mean()\n",
    "        a2 = df_scores.loc[df_scores.index != 'all', 'outOfPatternMissClassified'].mean()\n",
    "        df_scores.loc['all_mean', :] = [0, 0, total_images, a1, a2]\n",
    "\n",
    "        if bdd_col=='bdd':\n",
    "            return df_scores.reset_index()\n",
    "        return df_scores\n",
    "\n",
    "\n",
    "    def score_dataframe_multi_eta(self, df, eta):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_scores = pd.DataFrame()\n",
    "\n",
    "        for et in range(eta+1):\n",
    "            temp = self.score_dataframe(df, f'bdd_{et}')\n",
    "            temp['eta'] = et\n",
    "            temp.columns = [*map(lambda x: x.replace(f'bdd_{et}', ''), temp.columns)]\n",
    "            df_scores = pd.concat([df_scores, temp])\n",
    "            del temp\n",
    "\n",
    "        return df_scores.reset_index()\n",
    "\n",
    "\n",
    "    def plot_stats(self, df, stage, true=True, save_folder=None, prefix=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df = df.loc[df['true'] == true].set_index('y')\n",
    "        mean_ = df['outOfPattern'].mean().round(3)\n",
    "\n",
    "        neurons = f' Number of neuron: {len(self.neurons)}' if self.neurons is not None else None\n",
    "        title = f'{stage} - {true} - #out of pattern: {mean_}{neurons}\\n'\n",
    "        filename = f'{stage.lower()}_{true}_outOfPattern'\n",
    "        color = 'teal' if true else 'orange'\n",
    "\n",
    "        df['outOfPattern'].plot(\n",
    "            kind='bar', title=title, legend=False, color=color, xlabel='', hatch='x', edgecolor='black')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.axhline(mean_, color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "\n",
    "        if save_folder is not None:\n",
    "            plt.savefig(save_folder / f'bdd_scores_{filename}_{prefix}.jpg', dpi=150, transparent=False)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def build_bdd_multi_etas(args):\n",
    "    df_train, df_test, df_true, neurons, thld_name, thld, eta, save_path = args\n",
    "\n",
    "    from dd.autoref import BDD\n",
    "\n",
    "    # construcr MonitorBDD\n",
    "    patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons )\n",
    "    print(f'{thld_name} - eta: {eta}')\n",
    "\n",
    "    # build\n",
    "    patterns.add_dataframe( df_true, eta, eval_dfs=[df_train, df_test] )\n",
    "\n",
    "    # collect scores\n",
    "    df_bdd_info = patterns.stats.copy()\n",
    "    df_bdd_info['thld'] = thld_name\n",
    "\n",
    "    df_train_scores = patterns.score_dataframe_multi_eta(df_train, eta)\n",
    "    df_test_scores = patterns.score_dataframe_multi_eta(df_test, eta)\n",
    "    df_train_scores['stage'] = 'train'\n",
    "    df_test_scores['stage'] = 'test'\n",
    "\n",
    "    # combine scores\n",
    "    df_bdd_scores = pd.concat([df_train_scores, df_test_scores]).reset_index(drop=True)\n",
    "    df_bdd_scores['thld'] = thld_name\n",
    "\n",
    "    # delete variables\n",
    "    if save_path is not None:\n",
    "        temp_name = f'multi-etas-{thld_name}{\"-neurons\" if neurons else \"\"}'\n",
    "\n",
    "        with open(save_path / f'{temp_name}.pkl', \"wb\") as f:\n",
    "            pickle.dump(patterns, f, pickle.HIGHEST_PROTOCOL)\n",
    "        df_bdd_info.to_csv(save_path / f'{temp_name}-info.csv', index=False)\n",
    "        df_bdd_scores.to_csv(save_path / f'{temp_name}-scores.csv', index=False)\n",
    "\n",
    "    del BDD, patterns\n",
    "    del df_train_scores, df_test_scores\n",
    "\n",
    "    print(f'> Done! [ {thld_name} - eta: {eta} ]')\n",
    "\n",
    "    return df_bdd_info, df_bdd_scores\n",
    "\n",
    "\n",
    "\n",
    "def build_bdd(args):\n",
    "    df_train, df_test, df_true, neurons, thld_name, thld, eta, save_path = args\n",
    "\n",
    "    from dd.autoref import BDD\n",
    "\n",
    "    # construcr MonitorBDD\n",
    "    patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons )\n",
    "    print(f'{thld_name} - eta: {eta}')\n",
    "\n",
    "    # build\n",
    "    patterns.add_dataframe( df_true, eta)\n",
    "\n",
    "    # collect scores\n",
    "    df_bdd_info = patterns.stats.copy()\n",
    "    df_bdd_info['thld'] = thld_name\n",
    "\n",
    "    df_train_scores = patterns.evaluate_dataframe(df_train)\n",
    "    df_test_scores = patterns.evaluate_dataframe(df_test)\n",
    "\n",
    "    df_train_scores['stage'] = 'train'\n",
    "    df_train_scores['eta'] = eta\n",
    "\n",
    "    df_test_scores['stage'] = 'test'\n",
    "    df_test_scores['eta'] = eta\n",
    "\n",
    "    # combine scores\n",
    "    df_bdd_scores = pd.concat([df_train_scores, df_test_scores]).reset_index(drop=True)\n",
    "    df_bdd_scores['thld'] = thld_name\n",
    "\n",
    "    if save_path is not None:\n",
    "        temp_name = f'single-{thld_name}{\"-neurons\" if neurons else \"\"}'\n",
    "\n",
    "        with open(save_path / f'{temp_name}.pkl', \"wb\") as f:\n",
    "            pickle.dump(patterns, f, pickle.HIGHEST_PROTOCOL)\n",
    "        df_bdd_info.to_csv(save_path / f'{temp_name}-info.csv', index=False)\n",
    "        df_bdd_scores.to_csv(save_path / f'{temp_name}-scores.csv', index=False)\n",
    "\n",
    "    # delete variables\n",
    "    del BDD, patterns\n",
    "    del df_train_scores, df_test_scores\n",
    "\n",
    "    print(f'> Done! [ {thld_name} - eta: {eta} ]')\n",
    "\n",
    "    return df_bdd_info, df_bdd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd5d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define threshold\n",
    "\n",
    "p = 0.9\n",
    "\n",
    "thld = np.quantile(df_true.drop('y', axis=1), p, axis=0)\n",
    "thld_name = f'qth_{p}'\n",
    "\n",
    "# degree of freedom\n",
    "eta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52d67108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying thresholds ... \n",
      "Adding patterns with no degree of freedom ... \n",
      "Done!\n",
      "[==================================================]\n"
     ]
    }
   ],
   "source": [
    "monitor = MonitorBDD( 30, thld, neurons=neurons )\n",
    "\n",
    "monitor.add_dataframe( df_true, eta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "272bb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bdd_test = monitor.evaluate_dataframe( df_test, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb6560",
   "metadata": {},
   "source": [
    "#### Score Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "632c0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_out_of_pattern_images = df_test.loc[df_test['bdd_0'] == 0, ['y', 'bdd_0']].groupby('y').count().sort_index()\n",
    "df_test_out_of_pattern_images.columns = ['bdd_0' + '_false']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6785fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_out_of_pattern_misclassified_images = df_test.loc[(df_test['bdd_0'] == 0) & (df_test['true'] == False), ['y', 'bdd_0']].groupby('y').count().sort_index()\n",
    "df_test_out_of_pattern_misclassified_images.columns = ['bdd_0' + '_false_miss_classified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c46fd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scores = df_test_out_of_pattern_images.join(df_test_out_of_pattern_misclassified_images).join(df_test['y'].value_counts())\n",
    "df_test_scores.rename({'y': 'count'}, axis=1, inplace=True)\n",
    "del df_test_out_of_pattern_images, df_test_out_of_pattern_misclassified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "784a5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = df_test.shape[0]\n",
    "out_of_pattern_images = (df_test['bdd_0'] == 0).sum()\n",
    "out_of_pattern_misclassified_images = ((df_test['true'] == False) & (df_test['bdd_0'] == 0)).sum()\n",
    "df_test_scores.loc['all', :] = [out_of_pattern_images, out_of_pattern_misclassified_images, total_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5334e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "\n",
    "# df_test_scores.loc[0, 'bdd_0_false'] = 0\n",
    "# df_test_scores.loc[1, 'bdd_0_false_miss_classified'] = 0\n",
    "# df_test_scores.loc[2, 'bdd_0_false'] = 0\n",
    "# df_test_scores.loc[2, 'bdd_0_false_miss_classified'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5765775e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdd_0_false</th>\n",
       "      <th>bdd_0_false_miss_classified</th>\n",
       "      <th>count</th>\n",
       "      <th>outOfPattern</th>\n",
       "      <th>outOfPatternMissClassified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bdd_0_false  bdd_0_false_miss_classified    count  outOfPattern  \\\n",
       "y                                                                           \n",
       "0                 3.0                          0.0    980.0      0.003061   \n",
       "2                 5.0                          0.0   1032.0      0.004845   \n",
       "3                 9.0                          0.0   1010.0      0.008911   \n",
       "4                 1.0                          0.0    982.0      0.001018   \n",
       "5                 1.0                          0.0    892.0      0.001121   \n",
       "6                 9.0                          0.0    958.0      0.009395   \n",
       "8                 4.0                          1.0    974.0      0.004107   \n",
       "9                 3.0                          0.0   1009.0      0.002973   \n",
       "all              35.0                          1.0  10000.0      0.003500   \n",
       "all_mean          0.0                          0.0  10000.0      0.004429   \n",
       "\n",
       "          outOfPatternMissClassified  \n",
       "y                                     \n",
       "0                           1.000000  \n",
       "2                           1.000000  \n",
       "3                           1.000000  \n",
       "4                           1.000000  \n",
       "5                           1.000000  \n",
       "6                           1.000000  \n",
       "8                           0.250000  \n",
       "9                           1.000000  \n",
       "all                         0.028571  \n",
       "all_mean                    0.906250  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores['outOfPattern'] = df_test_scores['bdd_0' + '_false'] / df_test_scores['count']\n",
    "df_test_scores['outOfPatternMissClassified'] = df_test_scores['bdd_0' + '_false_miss_classified'] / df_test_scores['bdd_0' + '_false']\n",
    "\n",
    "df_test_scores['outOfPatternMissClassified'].replace({np.nan:1.0, 0.0: 1.0}, inplace=True)\n",
    "df_test_scores['bdd_0_false'].replace({np.nan:0.0}, inplace=True)\n",
    "df_test_scores['bdd_0_false_miss_classified'].replace({np.nan:0.0}, inplace=True)\n",
    "df_test_scores['outOfPattern'].replace({np.nan:0.0}, inplace=True)\n",
    "\n",
    "a1 = df_test_scores.loc[df_test_scores.index != 'all', 'outOfPattern'].mean()\n",
    "a2 = df_test_scores.loc[df_test_scores.index != 'all', 'outOfPatternMissClassified'].mean()\n",
    "\n",
    "df_test_scores.loc['all_mean', :] = [0, 0, total_images, a1, a2]\n",
    "\n",
    "df_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08ef5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
