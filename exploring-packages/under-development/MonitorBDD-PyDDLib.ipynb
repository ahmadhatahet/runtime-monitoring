{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WdOYGPWCPFDT"
   },
   "outputs": [],
   "source": [
    "# PyDDLib\n",
    "# https://github.com/thiagopbueno/pyddlib/blob/master/pyddlib/bdd.py\n",
    "\n",
    "# !pip install pyddlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tQJAylqCQ5L2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyddlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyddlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbdd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BDD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyddlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyddlib.bdd import BDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXVhcEhl2k_e"
   },
   "source": [
    "# Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yy81O5Yd2lcA"
   },
   "outputs": [],
   "source": [
    "vars = [BDD.variable(i) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxWJiDvQ5gRn",
    "outputId": "7332a0f7-e1b9-4cee-f320-cbffa8da24a6"
   },
   "outputs": [],
   "source": [
    "vars[0], ~vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_rruMKRx39CB"
   },
   "outputs": [],
   "source": [
    "img1 = vars[0] & ~vars[1] & vars[2]\n",
    "img2 = ~vars[0] & vars[1] & vars[2]\n",
    "dd = img1\n",
    "dd |= img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSqV_vIK3xwY",
    "outputId": "afc4e6d6-9e23-4206-ae06-1daf682b1b58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3 = ~vars[0] & vars[1] & ~vars[2]\n",
    "(dd & img3).is_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pU33u37eeA6",
    "outputId": "9a76c585-b957-4954-bd25-15f0b8eb6876"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3 = ~vars[0] & vars[1] & vars[2]\n",
    "(dd & img3).is_zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del BDD\n",
    "from pyddlib.bdd import BDD\n",
    "\n",
    "vars = [BDD.variable(i) for i in range(4)]\n",
    "vars_not = [~v for v in vars]\n",
    "\n",
    "fn = lambda row: np.where( row == 1, vars, vars_not )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important pass pattern as numpy array\n",
    "# otherwise will not work\n",
    "\n",
    "dd = BDD.zero() # initiate\n",
    "\n",
    "img1 = np.bitwise_and.reduce( fn(np.array([1, 0, 1, 1])) )\n",
    "dd = img1\n",
    "\n",
    "img2 = np.bitwise_and.reduce( fn(np.array([0, 1, 1, 1])) )\n",
    "dd |= img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3 = np.bitwise_and.reduce( fn(np.array([0, 1, 0, 1])) )\n",
    "(dd & img3).is_zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3 = np.bitwise_and.reduce( fn(np.array([0, 1, 1, 1])) )\n",
    "(dd & img3).is_zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YWM0PPFOnfI"
   },
   "source": [
    "# Monitor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FHl6lSv71roe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import asizeof\n",
    "import time\n",
    "\n",
    "class MonitorBDD:\n",
    "    def __init__(self, num_neurons, thld_1, thld_2=None, thld_3=None, neurons=None, verbose=False):\n",
    "        \n",
    "        from pyddlib.bdd import BDD\n",
    "\n",
    "        self.bdd = BDD.zero()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.thld_1 = thld_1\n",
    "        self.thld_2 = thld_2\n",
    "        self.thld_3 = thld_3\n",
    "        self.num_bits = 2 if thld_2 is not None or thld_3 is not None else 1\n",
    "        self.num_vars = num_neurons * self.num_bits\n",
    "\n",
    "        self.neurons = neurons\n",
    "        if self.neurons is not None:\n",
    "            self.neurons = np.array([int(n[1:]) for n in neurons])\n",
    "            self.thld_1 = thld_1[self.neurons]\n",
    "            self.thld_2 = thld_2[self.neurons] if self.thld_2 is not None else None\n",
    "            self.thld_3 = thld_3[self.neurons] if self.thld_3 is not None else None\n",
    "\n",
    "        self.vars, self.vars_not = self.__declare_vars()\n",
    "\n",
    "        self.stats = pd.DataFrame({\n",
    "            'thld': [],\n",
    "            'df': [],\n",
    "            'build_time': [],\n",
    "            'size_before_reorder_mb': [],\n",
    "            'reorder_time': [],\n",
    "            'size_after_reorder_mb': []\n",
    "        })\n",
    "\n",
    "\n",
    "    def __declare_vars(self):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # generate vars either x0_0 or x0_0 and x0_1 per neuron\n",
    "        if self.neurons is not None: vars_range = range(self.neurons.shape[0])\n",
    "        else: vars_range = range(self.num_neurons)\n",
    "\n",
    "        vars = np.array([self.bdd.variable(i) for i in vars_range])\n",
    "\n",
    "        # generate negative vars\n",
    "        vars_not = np.array([ ~v for v in vars ])\n",
    "\n",
    "        return vars, vars_not\n",
    "\n",
    "\n",
    "    def __multi_thlds(self, x):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        x = x.reshape(x.shape[0], 1)\n",
    "        x = np.where(x == [0], [0, 0], # 0\n",
    "             np.where(x == [1], [1, 0], # 1\n",
    "             np.where(x == [2], [0, 1], # 2\n",
    "             [1, 1] ) ) )# 3\n",
    "        return np.reshape(x, x.shape[0] * 2)\n",
    "\n",
    "\n",
    "    def __applying_thlds(self, df):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_thld = (df >=  self.thld_1).astype('int8')\n",
    "\n",
    "        if self.thld_2 is not None:\n",
    "            df_thld += (df >=  self.thld_2).astype('int8')\n",
    "\n",
    "        if self.thld_3 is not None:\n",
    "            df_thld += (df >=  self.thld_3).astype('int8')\n",
    "\n",
    "        return df_thld.to_numpy()\n",
    "\n",
    "\n",
    "    def check_pattern_length(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if self.num_bits == 2:\n",
    "            assert len(self.vars)/2 == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "        else:\n",
    "            assert len(self.vars) == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "\n",
    "\n",
    "    def construct_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # replace 1 with vars and 0 with vars_not\n",
    "        expr = np.where( row == 1, self.vars, self.vars_not )\n",
    "        return np.bitwise_and.reduce( expr )\n",
    "\n",
    "\n",
    "    def __add_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        self.bdd |= self.construct_pattern(row)\n",
    "\n",
    "\n",
    "    def flip_bit(self, patterns, eta):\n",
    "        \"\"\"flip n-th bit to allow more freedom(false positive)\n",
    "           if et = 0 then pattern as is\n",
    "           if et = 1 then loop over each bit and force it to one\n",
    "           et = 2 loop over 2 bits and flip them ... etc\n",
    "           drop any duplicate patterns\"\"\"\n",
    "\n",
    "        for nth in range(patterns.shape[1]-eta+1):\n",
    "            temp = patterns.copy()\n",
    "            temp[:, nth:nth+eta] = 1\n",
    "            temp = np.unique(temp, axis=0)\n",
    "            yield temp\n",
    "\n",
    "\n",
    "    def add_dataframe(self, df, eta=0, eval_dfs=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        if self.neurons is not None:\n",
    "            df = df[df.columns[self.neurons]].drop_duplicates()\n",
    "        else:\n",
    "            df = df[df.columns[:self.num_neurons]].drop_duplicates()\n",
    "\n",
    "        patterns = self.__applying_thlds(df)\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            self.__add_one_pattern(patterns[i])\n",
    "        build_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "\n",
    "        row = self.stats.shape[0]+1\n",
    "        self.stats.loc[row, 'df'] = 0\n",
    "        self.stats.loc[row, 'build_time'] = build_time\n",
    "        self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "        # add column for scoring\n",
    "        if eval_dfs is not None:\n",
    "            for eval_df in eval_dfs:\n",
    "                self.evaluate_dataframe(eval_df, 0)\n",
    "\n",
    "\n",
    "        start = time.perf_counter()\n",
    "#         BDD.reorder(self.bdd)\n",
    "        bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "        self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "        self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "\n",
    "        # flip bit\n",
    "        if eta > 0:\n",
    "            # evaluate starting from 1 degree of freedom\n",
    "            for et in range(1, eta+1):\n",
    "                row = self.stats.shape[0]+1\n",
    "                start = time.perf_counter()\n",
    "\n",
    "                # flip each neuron to 1 then add to BDD\n",
    "                for flipped_patterns in self.flip_bit(patterns, et):\n",
    "                    for i in range(flipped_patterns.shape[0]):\n",
    "                        self.__add_one_pattern(flipped_patterns[i])\n",
    "                    # end loop flipped_patterns\n",
    "\n",
    "                build_time = round(time.perf_counter() - start, 3)\n",
    "                self.stats.loc[row, 'df'] = et\n",
    "                self.stats.loc[row, 'build_time'] = build_time\n",
    "                self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # reorder\n",
    "                start = time.perf_counter()\n",
    "#                 BDD.reorder(self.bdd)\n",
    "                bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "                self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "                self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "                # add column for scoring\n",
    "                if eval_dfs is not None:\n",
    "                    for eval_df in eval_dfs:\n",
    "                        self.evaluate_dataframe(eval_df, et)\n",
    "\n",
    "        # return evaluated dataframes\n",
    "        if eval_dfs is not None:\n",
    "            return eval_dfs\n",
    "\n",
    "        self.stats = self.stats.loc[self.stats['df'] == eta]\n",
    "        return\n",
    "\n",
    "\n",
    "    def check_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if (self.bdd & self.construct_pattern(row) ).is_zero():\n",
    "            return 0 # means not found\n",
    "        else:\n",
    "            return 1 # found it\n",
    "\n",
    "\n",
    "    def evaluate_dataframe(self, df, eta=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        bdd_results = np.zeros(df.shape[0], dtype=np.int8)\n",
    "\n",
    "        if self.neurons is not None:\n",
    "            patterns = self.__applying_thlds(df[df.columns[self.neurons]])\n",
    "        else:\n",
    "            patterns = self.__applying_thlds(df[df.columns[:self.num_neurons]])\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            bdd_results[i] = self.check_one_pattern(patterns[i])\n",
    "\n",
    "        if eta is not None:\n",
    "            df[f'bdd_{eta}'] = bdd_results\n",
    "            return\n",
    "\n",
    "        # if the function called specifically, return scored df after evaluating\n",
    "        df['bdd'] = bdd_results\n",
    "\n",
    "        return self.score_dataframe(df)\n",
    "\n",
    "\n",
    "    def score_dataframe(self, df, bdd_col='bdd'):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_out_of_pattern_images = df.loc[df[bdd_col] == 0, ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_images.columns = [bdd_col + '_false']\n",
    "\n",
    "        df_out_of_pattern_misclassified_images = df.loc[(df[bdd_col] == 0) & (df['true'] == False), ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_misclassified_images.columns = [bdd_col + '_false_miss_classified']\n",
    "\n",
    "        df_scores = df_out_of_pattern_images.join(df_out_of_pattern_misclassified_images).join(df['y'].value_counts())\n",
    "        df_scores.rename({'y': 'count'}, axis=1, inplace=True)\n",
    "\n",
    "        del df_out_of_pattern_images, df_out_of_pattern_misclassified_images\n",
    "\n",
    "        total_images = df.shape[0]\n",
    "        out_of_pattern_images = (df[bdd_col] == 0).sum()\n",
    "        out_of_pattern_misclassified_images = ((df['true'] == False) & (df[bdd_col] == 0)).sum()\n",
    "        df_scores.loc['all', :] = [out_of_pattern_images, out_of_pattern_misclassified_images, total_images]\n",
    "        # if data frame return 0 rows, a nan will be placed\n",
    "        df_scores.fillna(0, inplace=True)\n",
    "        # calculate metrics\n",
    "        df_scores['outOfPattern'] = df_scores[bdd_col + '_false'] / df_scores['count']\n",
    "        df_scores['outOfPatternMissClassified'] = df_scores[bdd_col + '_false_miss_classified'] / df_scores[bdd_col + '_false']\n",
    "        # if class is never missclassified and bdd recognize all of his patterns\n",
    "        # both outOfPattern and outOfPatternMissClassified will be 0\n",
    "        # so the division will result in NaN\n",
    "        df_scores['outOfPatternMissClassified'].replace({np.nan:1.0, 0.0: 1.0}, inplace=True)\n",
    "        df_scores['outOfPattern'].replace({np.nan:0.0}, inplace=True)\n",
    "        # no missclassification for a class\n",
    "        df_scores[bdd_col + '_false'].replace({np.nan:0.0}, inplace=True)\n",
    "        df_scores[bdd_col + '_false_miss_classified'].replace({np.nan:0.0}, inplace=True)\n",
    "        # add mean of all classes\n",
    "        a1 = df_scores.loc[df_scores.index != 'all', 'outOfPattern'].mean()\n",
    "        a2 = df_scores.loc[df_scores.index != 'all', 'outOfPatternMissClassified'].mean()\n",
    "        df_scores.loc['all_mean', :] = [0, 0, total_images, a1, a2]\n",
    "\n",
    "        if bdd_col=='bdd':\n",
    "            return df_scores.reset_index()\n",
    "        return df_scores\n",
    "\n",
    "\n",
    "    def score_dataframe_multi_eta(self, df, eta):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_scores = pd.DataFrame()\n",
    "\n",
    "        for et in range(eta+1):\n",
    "            temp = self.score_dataframe(df, f'bdd_{et}')\n",
    "            temp['eta'] = et\n",
    "            temp.columns = [*map(lambda x: x.replace(f'bdd_{et}', ''), temp.columns)]\n",
    "            df_scores = pd.concat([df_scores, temp])\n",
    "            del temp\n",
    "\n",
    "        return df_scores.reset_index()\n",
    "\n",
    "\n",
    "    def plot_stats(self, df, stage, true=True, save_folder=None, prefix=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df = df.loc[df['true'] == true].set_index('y')\n",
    "        mean_ = df['outOfPattern'].mean().round(3)\n",
    "\n",
    "        neurons = f' Number of neuron: {len(self.neurons)}' if self.neurons is not None else None\n",
    "        title = f'{stage} - {true} - #out of pattern: {mean_}{neurons}\\n'\n",
    "        filename = f'{stage.lower()}_{true}_outOfPattern'\n",
    "        color = 'teal' if true else 'orange'\n",
    "\n",
    "        df['outOfPattern'].plot(\n",
    "            kind='bar', title=title, legend=False, color=color, xlabel='', hatch='x', edgecolor='black')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.axhline(mean_, color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "\n",
    "        if save_folder is not None:\n",
    "            plt.savefig(save_folder / f'bdd_scores_{filename}_{prefix}.jpg', dpi=150, transparent=False)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def build_bdd_multi_etas(args):\n",
    "    df_train, df_test, df_true, neurons, thld_name, thld, eta, save_path = args\n",
    "\n",
    "    from dd.autoref import BDD\n",
    "\n",
    "    # construcr MonitorBDD\n",
    "    patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons )\n",
    "    print(f'{thld_name} - eta: {eta}')\n",
    "\n",
    "    # build\n",
    "    patterns.add_dataframe( df_true, eta, eval_dfs=[df_train, df_test] )\n",
    "\n",
    "    # collect scores\n",
    "    df_bdd_info = patterns.stats.copy()\n",
    "    df_bdd_info['thld'] = thld_name\n",
    "\n",
    "    df_train_scores = patterns.score_dataframe_multi_eta(df_train, eta)\n",
    "    df_test_scores = patterns.score_dataframe_multi_eta(df_test, eta)\n",
    "    df_train_scores['stage'] = 'train'\n",
    "    df_test_scores['stage'] = 'test'\n",
    "\n",
    "    # combine scores\n",
    "    df_bdd_scores = pd.concat([df_train_scores, df_test_scores]).reset_index(drop=True)\n",
    "    df_bdd_scores['thld'] = thld_name\n",
    "\n",
    "    # delete variables\n",
    "    if save_path is not None:\n",
    "        temp_name = f'multi-etas-{thld_name}{\"-neurons\" if neurons else \"\"}'\n",
    "\n",
    "        with open(save_path / f'{temp_name}.pkl', \"wb\") as f:\n",
    "            pickle.dump(patterns, f, pickle.HIGHEST_PROTOCOL)\n",
    "        df_bdd_info.to_csv(save_path / f'{temp_name}-info.csv', index=False)\n",
    "        df_bdd_scores.to_csv(save_path / f'{temp_name}-scores.csv', index=False)\n",
    "\n",
    "    del BDD, patterns\n",
    "    del df_train_scores, df_test_scores\n",
    "\n",
    "    print(f'> Done! [ {thld_name} - eta: {eta} ]')\n",
    "\n",
    "    return df_bdd_info, df_bdd_scores\n",
    "\n",
    "\n",
    "\n",
    "def build_bdd(args):\n",
    "    df_train, df_test, df_true, neurons, thld_name, thld, eta, save_path = args\n",
    "\n",
    "    from dd.autoref import BDD\n",
    "\n",
    "    # construcr MonitorBDD\n",
    "    patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons )\n",
    "    print(f'{thld_name} - eta: {eta}')\n",
    "\n",
    "    # build\n",
    "    patterns.add_dataframe( df_true, eta)\n",
    "\n",
    "    # collect scores\n",
    "    df_bdd_info = patterns.stats.copy()\n",
    "    df_bdd_info['thld'] = thld_name\n",
    "\n",
    "    df_train_scores = patterns.evaluate_dataframe(df_train)\n",
    "    df_test_scores = patterns.evaluate_dataframe(df_test)\n",
    "\n",
    "    df_train_scores['stage'] = 'train'\n",
    "    df_train_scores['eta'] = eta\n",
    "\n",
    "    df_test_scores['stage'] = 'test'\n",
    "    df_test_scores['eta'] = eta\n",
    "\n",
    "    # combine scores\n",
    "    df_bdd_scores = pd.concat([df_train_scores, df_test_scores]).reset_index(drop=True)\n",
    "    df_bdd_scores['thld'] = thld_name\n",
    "\n",
    "    if save_path is not None:\n",
    "        temp_name = f'single-{thld_name}{\"-neurons\" if neurons else \"\"}'\n",
    "\n",
    "        with open(save_path / f'{temp_name}.pkl', \"wb\") as f:\n",
    "            pickle.dump(patterns, f, pickle.HIGHEST_PROTOCOL)\n",
    "        df_bdd_info.to_csv(save_path / f'{temp_name}-info.csv', index=False)\n",
    "        df_bdd_scores.to_csv(save_path / f'{temp_name}-scores.csv', index=False)\n",
    "\n",
    "    # delete variables\n",
    "    del BDD, patterns\n",
    "    del df_train_scores, df_test_scores\n",
    "\n",
    "    print(f'> Done! [ {thld_name} - eta: {eta} ]')\n",
    "\n",
    "    return df_bdd_info, df_bdd_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c61R23U_1rma"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B6iVW9-q1rkc"
   },
   "outputs": [],
   "source": [
    "# env variables\n",
    "REPO_PATH = '/home/ah19/runtime-monitoring'\n",
    "DATASET = 'MNIST'\n",
    "PREFIX = 'Adam-256-30'\n",
    "FILENAME_POSTFIX = f'{DATASET}_{PREFIX}'\n",
    "DATA_FALVOR = 'raw'\n",
    "LOAD_NEURONS = True\n",
    "POSTFIX = 'PyDDLib'\n",
    "NUM_NEURONS = int(PREFIX.split('-')[-1])\n",
    "\n",
    "sys.path.append(f'{REPO_PATH}/utilities')\n",
    "from utils import load_json\n",
    "from pathManager import fetchPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PynxGpqK1rif"
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "base = Path(REPO_PATH)\n",
    "paths = fetchPaths(base, DATASET)\n",
    "\n",
    "path = paths[DATASET.lower()]\n",
    "path_bdd_testingThresholds_raw = paths['bdd_testingThresholds_raw'] / FILENAME_POSTFIX\n",
    "\n",
    "\n",
    "# path_lastHiddenLayer = paths['lastHiddenLayer']\n",
    "# path_lastHiddenLayer_raw = paths['lastHiddenLayer_raw']\n",
    "path_lastHiddenLayer_pca = paths['lastHiddenLayer_pca']\n",
    "path_lastHiddenLayer_pca_single = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Single'\n",
    "# path_lastHiddenLayer_pca_classes = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Classes'\n",
    "\n",
    "path_lastHiddenLayer = paths['lastHiddenLayer_raw'] / FILENAME_POSTFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hs-DGYfE1rgc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train Data ...\n",
      "Loading test Data ...\n",
      "Loading Neurons ...\n"
     ]
    }
   ],
   "source": [
    "# import Data\n",
    "print('Loading train Data ...')\n",
    "df = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_train.csv')\n",
    "\n",
    "# split train data\n",
    "df_true = df[df['true'] == True].copy()\n",
    "df_true = df_true.drop('true', axis=1).reset_index(drop=True)\n",
    "\n",
    "print('Loading test Data ...')\n",
    "df_test = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_test.csv')\n",
    "\n",
    "\n",
    "print('Loading Neurons ...')\n",
    "neurons = None\n",
    "if LOAD_NEURONS:\n",
    "    neurons = load_json(path_lastHiddenLayer_pca_single / f'{FILENAME_POSTFIX}_neurons.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e4EBywWv1reO"
   },
   "outputs": [],
   "source": [
    "# define threshold\n",
    "\n",
    "p = 0.9\n",
    "\n",
    "thld = np.quantile(df_true.drop('y', axis=1), p, axis=0)\n",
    "thld_name = f'qth_{p}'\n",
    "\n",
    "# degree of freedom\n",
    "eta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y3v1Cgtp1rcP"
   },
   "outputs": [],
   "source": [
    "# monitor = MonitorBDD( NUM_NEURONS, thld, neurons=neurons )\n",
    "monitor = MonitorBDD( NUM_NEURONS, thld )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor.vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.add_dataframe( df_true, eta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YguI8ine1raV"
   },
   "outputs": [],
   "source": [
    "df_bdd_test = monitor.evaluate_dataframe( df_test, 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CFvlJ-nk1rYj"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9f281a557f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_bdd_test_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_bdd_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5eb7517f63cc>\u001b[0m in \u001b[0;36mscore_dataframe\u001b[0;34m(self, df, bdd_col)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbdd_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bdd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;34m\"\"\"TODO\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mdf_out_of_pattern_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbdd_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbdd_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mdf_out_of_pattern_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbdd_col\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_false'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "df_bdd_test_score = monitor.score_dataframe(df_bdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xA272twi1rWn"
   },
   "outputs": [],
   "source": [
    "df_bdd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sIjPc-e1rUm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcMGGOcK1rJT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nHQ1J-x1rHO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJJHzsXi1rD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjUTYmEL1q_k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
