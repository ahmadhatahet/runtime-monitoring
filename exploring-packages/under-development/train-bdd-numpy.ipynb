{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7f5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff685c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env variables\n",
    "REPO_PATH = '/home/ah19/runtime-monitoring'\n",
    "DATASET = 'FashionMNIST'\n",
    "PREFIX = 'Adam-128-100'\n",
    "FILENAME_POSTFIX = f'{DATASET}_{PREFIX}'\n",
    "DATA_FALVOR = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19365b3-d648-4f83-b527-cafe5ede2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n",
    "from utilities.utils import load_json\n",
    "from utilities.pathManager import fetchPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f97ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base = Path(REPO_PATH)\n",
    "paths = fetchPaths(base, DATASET)\n",
    "\n",
    "path = paths[DATASET.lower()]\n",
    "path_bdd = paths['bdd_' + DATA_FALVOR] / FILENAME_POSTFIX\n",
    "\n",
    "path_lastHiddenLayer_pca = paths['lastHiddenLayer_pca']\n",
    "path_lastHiddenLayer_pca_single = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Single'\n",
    "# path_lastHiddenLayer_pca_classes = path_lastHiddenLayer_pca / FILENAME_POSTFIX / 'Classes'\n",
    "\n",
    "save_path = paths['bdd_testingThresholds_' + DATA_FALVOR] / FILENAME_POSTFIX\n",
    "\n",
    "\n",
    "path_lastHiddenLayer = paths['lastHiddenLayer_' + DATA_FALVOR] / FILENAME_POSTFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae325d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train Data ...\n",
      "Loading test Data ...\n",
      "Loading Neurons ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import Data\n",
    "print('Loading train Data ...')\n",
    "df = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_train.csv')\n",
    "\n",
    "# split train data\n",
    "df_true = df[df['true'] == True].copy()\n",
    "df_true = df_true.drop('true', axis=1).reset_index(drop=True)\n",
    "\n",
    "print('Loading test Data ...')\n",
    "df_test = pd.read_csv(path_lastHiddenLayer / f'{FILENAME_POSTFIX}_test.csv')\n",
    "\n",
    "\n",
    "print('Loading Neurons ...')\n",
    "neurons = load_json(path_lastHiddenLayer_pca_single / f'{FILENAME_POSTFIX}_neurons.json')\n",
    "\n",
    "# neurons = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6df61088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dd.autoref import BDD\n",
    "from pympler import asizeof\n",
    "import time\n",
    "\n",
    "class MonitorBDD:\n",
    "    def __init__(self, num_neurons, thld_1, thld_2=None, thld_3=None, neurons=None, max_time=0, verbose=False):\n",
    "\n",
    "        self.bdd = BDD()\n",
    "        self.roots = self.bdd.false\n",
    "        self.num_neurons = num_neurons\n",
    "        self.verbose = verbose\n",
    "        self.max_time = max_time\n",
    "\n",
    "        self.thld_1 = thld_1\n",
    "        self.thld_2 = thld_2\n",
    "        self.thld_3 = thld_3\n",
    "        self.num_bits = 2 if thld_2 is not None or thld_3 is not None else 1\n",
    "        self.num_vars = num_neurons * self.num_bits\n",
    "\n",
    "        self.neurons = neurons\n",
    "        if self.neurons is not None:\n",
    "            self.neurons = np.array([int(n[1:]) for n in neurons])\n",
    "            self.thld_1 = thld_1[self.neurons]\n",
    "            self.thld_2 = thld_2[self.neurons] if self.thld_2 is not None else None\n",
    "            self.thld_3 = thld_3[self.neurons] if self.thld_3 is not None else None\n",
    "\n",
    "        self.vars, self.vars_not = self.__declare_vars()\n",
    "\n",
    "        self.stats = pd.DataFrame({\n",
    "            'thld': [],\n",
    "            'df': [],\n",
    "            'build_time': [],\n",
    "            'size_before_reorder_mb': [],\n",
    "            'reorder_time': [],\n",
    "            'size_after_reorder_mb': [],\n",
    "            'successful': []\n",
    "        })\n",
    "\n",
    "\n",
    "    def __declare_vars(self):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # generate vars either x0_0 or x0_0 and x0_1 per neuron\n",
    "        vars_range = self.neurons if self.neurons is not None else range(self.num_neurons)\n",
    "        v = [f'x{n}_{i}' for i in range(self.num_bits) for n in vars_range]\n",
    "\n",
    "        # add vars to bdd\n",
    "        [ *map(self.bdd.add_var, v) ]\n",
    "\n",
    "        # generate negative vars\n",
    "        vars = np.array([ *map(self.bdd.var, v) ])\n",
    "        vars_not = np.array([ ~v for v in vars ])\n",
    "\n",
    "        return vars, vars_not\n",
    "\n",
    "\n",
    "    def __multi_thlds(self, x):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        x = x.reshape(x.shape[0], 1)\n",
    "        x = np.where(x == [0], [0, 0], # 0\n",
    "             np.where(x == [1], [1, 0], # 1\n",
    "             np.where(x == [2], [0, 1], # 2\n",
    "             [1, 1] ) ) )# 3\n",
    "        return np.reshape(x, x.shape[0] * 2)\n",
    "\n",
    "\n",
    "    def __applying_thlds(self, df):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_thld = (df >=  self.thld_1).astype('int8')\n",
    "\n",
    "        if self.thld_2 is not None:\n",
    "            df_thld += (df >=  self.thld_2).astype('int8')\n",
    "\n",
    "        if self.thld_3 is not None:\n",
    "            df_thld += (df >=  self.thld_3).astype('int8')\n",
    "\n",
    "        return df_thld.to_numpy()\n",
    "\n",
    "\n",
    "    def check_pattern_length(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if self.num_bits == 2:\n",
    "            assert len(self.vars)/2 == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "        else:\n",
    "            assert len(self.vars) == row.shape[0], \"ERROR: VARS and ROW do not match!\"\n",
    "\n",
    "\n",
    "    def construct_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        # replace 1 with vars and 0 with vars_not\n",
    "        expr = np.where( row == 1, self.vars, self.vars_not )\n",
    "        return np.bitwise_and.reduce(expr)\n",
    "    \n",
    "\n",
    "    def __add_patterns(self, rows):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        self.roots |= np.bitwise_or.reduce( np.apply_along_axis(self.construct_one_pattern, 1, rows) )\n",
    "\n",
    "\n",
    "\n",
    "    def flip_bit(self, patterns, eta):\n",
    "        \"\"\"flip n-th bit to allow more freedom(false positive)\n",
    "           if et = 0 then pattern as is\n",
    "           if et = 1 then loop over each bit and force it to one\n",
    "           et = 2 loop over 2 bits and flip them ... etc\n",
    "           drop any duplicate patterns\"\"\"\n",
    "\n",
    "        for nth in range(patterns.shape[1]-eta+1):\n",
    "            temp = patterns.copy()\n",
    "            temp[:, nth:nth+eta] = 1\n",
    "            temp = np.unique(temp, axis=0)\n",
    "            yield temp\n",
    "\n",
    "\n",
    "    def add_dataframe(self, df, eta=0, eval_dfs=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        if self.neurons is not None:\n",
    "            df = df[df.columns[self.neurons]].drop_duplicates()\n",
    "        else:\n",
    "            df = df[df.columns[:self.num_neurons]].drop_duplicates()\n",
    "\n",
    "        patterns = self.__applying_thlds(df)\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "        self.__add_patterns(patterns)\n",
    "        \n",
    "        \n",
    "        build_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "\n",
    "        row = self.stats.shape[0]+1\n",
    "        self.stats.loc[row, 'df'] = 0\n",
    "        \n",
    "        \n",
    "        self.stats.loc[row, 'build_time'] = build_time\n",
    "        self.stats.loc[row, 'size_before_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "        \n",
    "\n",
    "        start = time.perf_counter()\n",
    "        BDD.reorder(self.bdd)\n",
    "        bdd_reorder_time = round(time.perf_counter() - start, 3)\n",
    "\n",
    "        self.stats.loc[row, 'reorder_time'] = bdd_reorder_time\n",
    "        self.stats.loc[row, 'size_after_reorder_mb'] = round( asizeof.asizeof(self) * 1e-6, 3)\n",
    "\n",
    "        # add column for scoring\n",
    "        if eval_dfs is not None:\n",
    "            for eval_df in eval_dfs:\n",
    "                self.evaluate_dataframe(eval_df, 0)\n",
    "\n",
    "        # return evaluated dataframes\n",
    "        if eval_dfs is not None:\n",
    "            return eval_dfs\n",
    "\n",
    "        self.stats = self.stats.loc[self.stats['df'] == eta]\n",
    "        return\n",
    "\n",
    "\n",
    "    def check_one_pattern(self, row):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        if (self.roots & self.construct_one_pattern(row) ) == self.bdd.false:\n",
    "            return 0 # means not found\n",
    "        else:\n",
    "            return 1 # found it\n",
    "\n",
    "\n",
    "    def evaluate_dataframe(self, df, eta=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        bdd_results = np.zeros(df.shape[0], dtype=np.int8)\n",
    "\n",
    "        if self.neurons is not None:\n",
    "            patterns = self.__applying_thlds(df[df.columns[self.neurons]])\n",
    "        else:\n",
    "            patterns = self.__applying_thlds(df[df.columns[:self.num_neurons]])\n",
    "\n",
    "        if self.num_bits == 2:\n",
    "            patterns = np.apply_along_axis(self.__multi_thlds, 1, patterns)\n",
    "\n",
    "        bdd_results = np.apply_along_axis(self.check_one_pattern, 1, patterns)\n",
    "\n",
    "        if eta is not None:\n",
    "            df[f'bdd_{eta}'] = bdd_results\n",
    "            return\n",
    "\n",
    "        # if the function called specifically, return scored df after evaluating\n",
    "        df['bdd'] = bdd_results\n",
    "\n",
    "        return self.score_dataframe(df)\n",
    "\n",
    "\n",
    "    def score_dataframe(self, df, bdd_col='bdd'):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        \n",
    "        if bdd_col not in df.columns:\n",
    "            return pd.DataFrame({\n",
    "                        'y': []\n",
    "                        ,'count': []\n",
    "                        ,'_false': []\n",
    "                        ,'_false_miss_classified': []\n",
    "                        ,'outOfPattern': []\n",
    "                        ,'outOfPatternMissClassified': []\n",
    "                        ,'eta':[]\n",
    "                    })\n",
    "        \n",
    "        df_all_classes = df[['y', 'true']].groupby('y').count().sort_index()\n",
    "        df_all_classes.columns = ['count']\n",
    "\n",
    "        df_out_of_pattern_images = df.loc[df[bdd_col] == 0, ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_images.columns = [bdd_col + '_false']\n",
    "\n",
    "        df_out_of_pattern_misclassified_images = df.loc[(df[bdd_col] == 0) & (df['true'] == False), ['y', bdd_col]].groupby('y').count().sort_index()\n",
    "        df_out_of_pattern_misclassified_images.columns = [bdd_col + '_false_miss_classified']\n",
    "\n",
    "        df_scores = df_all_classes.join(df_out_of_pattern_images).join(df_out_of_pattern_misclassified_images)\n",
    "\n",
    "        del df_out_of_pattern_images, df_out_of_pattern_misclassified_images\n",
    "\n",
    "        total_images = df_all_classes['count'].sum()\n",
    "        out_of_pattern_images = (df[bdd_col] == 0).sum()\n",
    "        out_of_pattern_misclassified_images = ((df['true'] == False) & (df[bdd_col] == 0)).sum()\n",
    "        df_scores.loc['all', :] = [total_images, out_of_pattern_images, out_of_pattern_misclassified_images]\n",
    "\n",
    "        # if data frame return 0 rows, a nan will be placed\n",
    "        df_scores.fillna(0, inplace=True)\n",
    "\n",
    "        # calculate metrics\n",
    "        df_scores['outOfPattern'] = df_scores[bdd_col + '_false'] / df_scores['count']\n",
    "        df_scores['outOfPatternMissClassified'] = df_scores[bdd_col + '_false_miss_classified'] / df_scores[bdd_col + '_false']\n",
    "\n",
    "        # add mean of all classes\n",
    "        a1 = df_scores.loc[df_scores.index != 'all', 'outOfPattern'].mean()\n",
    "        a2 = df_scores.loc[df_scores.index != 'all', 'outOfPatternMissClassified'].mean()\n",
    "        df_scores.loc['all_mean', :] = [0, 0, total_images, a1, a2]\n",
    "\n",
    "        # if class is never missclassified and bdd recognize all of his patterns\n",
    "        # both outOfPattern and outOfPatternMissClassified will be 0\n",
    "        # so the division will result in NaN\n",
    "        df_scores['outOfPatternMissClassified'].replace({np.nan:0.0, 0.0:1.0}, inplace=True)\n",
    "        df_scores['outOfPattern'].replace({np.nan:0.0}, inplace=True)\n",
    "\n",
    "        # no missclassification for a class\n",
    "        df_scores[bdd_col + '_false'].replace({np.nan:0.0}, inplace=True)\n",
    "        df_scores[bdd_col + '_false_miss_classified'].replace({np.nan:0.0}, inplace=True)\n",
    "\n",
    "        if bdd_col=='bdd':\n",
    "            return df_scores.reset_index()\n",
    "        return df_scores\n",
    "\n",
    "\n",
    "    def score_dataframe_multi_eta(self, df, eta):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df_scores = pd.DataFrame()\n",
    "\n",
    "        for et in range(eta+1):\n",
    "            temp = self.score_dataframe(df, f'bdd_{et}')\n",
    "            temp['eta'] = et\n",
    "            temp.columns = [*map(lambda x: x.replace(f'bdd_{et}', ''), temp.columns)]\n",
    "            df_scores = pd.concat([df_scores, temp])\n",
    "            del temp\n",
    "\n",
    "        return df_scores.reset_index()\n",
    "\n",
    "\n",
    "    def plot_stats(self, df, stage, true=True, save_folder=None, prefix=None):\n",
    "        \"\"\"TODO\"\"\"\n",
    "        df = df.loc[df['true'] == true].set_index('y')\n",
    "        mean_ = df['outOfPattern'].mean().round(3)\n",
    "\n",
    "        neurons = f' Number of neuron: {len(self.neurons)}' if self.neurons is not None else None\n",
    "        title = f'{stage} - {true} - #out of pattern: {mean_}{neurons}\\n'\n",
    "        filename = f'{stage.lower()}_{true}_outOfPattern'\n",
    "        color = 'teal' if true else 'orange'\n",
    "\n",
    "        df['outOfPattern'].plot(\n",
    "            kind='bar', title=title, legend=False, color=color, xlabel='', hatch='x', edgecolor='black')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.axhline(mean_, color='red', linewidth=2, linestyle='--')\n",
    "\n",
    "\n",
    "        if save_folder is not None:\n",
    "            plt.savefig(save_folder / f'bdd_scores_{filename}_{prefix}.jpg', dpi=150, transparent=False)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define threshold\n",
    "\n",
    "p = 0.3\n",
    "\n",
    "thld = np.quantile(df_true.drop('y', axis=1), p, axis=0)\n",
    "thld_name = f'qth_{p}'\n",
    "\n",
    "# degree of freedom\n",
    "eta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36fce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = MonitorBDD( df_true.shape[1]-1, thld, neurons=neurons, max_time=10 )\n",
    "df_2, df_test_2 = patterns.add_dataframe( df_true, eta, eval_dfs=[df.copy(), df_test.copy()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b15617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thld</th>\n",
       "      <th>df</th>\n",
       "      <th>build_time</th>\n",
       "      <th>size_before_reorder_mb</th>\n",
       "      <th>reorder_time</th>\n",
       "      <th>size_after_reorder_mb</th>\n",
       "      <th>successful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>854.316</td>\n",
       "      <td>24582.464</td>\n",
       "      <td>4460.514</td>\n",
       "      <td>8151.266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thld   df  build_time  size_before_reorder_mb  reorder_time  \\\n",
       "1   NaN  0.0     854.316               24582.464      4460.514   \n",
       "\n",
       "   size_after_reorder_mb  successful  \n",
       "1               8151.266         NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a754cf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>count</th>\n",
       "      <th>_false</th>\n",
       "      <th>_false_miss_classified</th>\n",
       "      <th>outOfPattern</th>\n",
       "      <th>outOfPatternMissClassified</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.103103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.052183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.065327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9513.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.066604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y    count  _false  _false_miss_classified  outOfPattern  \\\n",
       "0          0   1000.0   996.0                   150.0        0.9960   \n",
       "1          1   1000.0   780.0                    18.0        0.7800   \n",
       "2          2   1000.0   999.0                   103.0        0.9990   \n",
       "3          3   1000.0   939.0                    49.0        0.9390   \n",
       "4          4   1000.0   995.0                    65.0        0.9950   \n",
       "5          5   1000.0   942.0                     8.0        0.9420   \n",
       "6          6   1000.0   993.0                   193.0        0.9930   \n",
       "7          7   1000.0   957.0                    27.0        0.9570   \n",
       "8          8   1000.0   950.0                    11.0        0.9500   \n",
       "9          9   1000.0   962.0                    28.0        0.9620   \n",
       "10       all  10000.0  9513.0                   652.0        0.9513   \n",
       "11  all_mean      0.0     0.0                 10000.0        0.9513   \n",
       "\n",
       "    outOfPatternMissClassified  eta  \n",
       "0                     0.150602    0  \n",
       "1                     0.023077    0  \n",
       "2                     0.103103    0  \n",
       "3                     0.052183    0  \n",
       "4                     0.065327    0  \n",
       "5                     0.008493    0  \n",
       "6                     0.194361    0  \n",
       "7                     0.028213    0  \n",
       "8                     0.011579    0  \n",
       "9                     0.029106    0  \n",
       "10                    0.068538    0  \n",
       "11                    0.066604    0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = patterns.score_dataframe_multi_eta(df_test_2, eta)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b000a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
