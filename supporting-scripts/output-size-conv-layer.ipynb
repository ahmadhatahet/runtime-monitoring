{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f77a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55dafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3,bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 64, 3,bias=False),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d5e9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "102f2579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.zeros((2, 3, 32, 32))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae10d9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 28, 28])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcdf0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (h_w[0] + (2 * pad[0]) - (dilation * (kernel_size[0] - 1)) - 1)// stride[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ce7d516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].in_channels, model[0].out_channels, model[0].kernel_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef04225b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].padding[0], model[0].stride[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102a2cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.modules.pooling.MaxPool2d, torch.nn.modules.pooling.AvgPool2d)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MaxPool2d, nn.AvgPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0385850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(h_w, layer):\n",
    "    return (h_w + (2 * layer.padding[0]) - (1 * (layer.kernel_size[0] - 1)) - 1)// layer.stride[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0920a7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(32, model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2638ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "h_w = 32\n",
    "\n",
    "for layer in model:\n",
    "    h_w = calc(h_w, layer)\n",
    "    print(h_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2e2fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "Conv2d\n"
     ]
    }
   ],
   "source": [
    "for layer in model:\n",
    "    print(type(layer).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962a8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FashionMNIST_CNN(nn.Module):\n",
    "    def __init__(self, channels=1, img_dim=28, outneurons=10, last_hidden_neurons=40, first_layer_norm=False,\n",
    "        weight_init=\"kaiming_uniform\", bias=True, dropout=0.0, batchnorm=True):\n",
    "\n",
    "        super(FashionMNIST_CNN, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.img_dim = img_dim\n",
    "        self.in_features = channels * img_dim * img_dim\n",
    "        self.num_classes = outneurons\n",
    "        self.last_hidden_neurons = last_hidden_neurons\n",
    "        self.dropout_p = dropout\n",
    "        self.batchnorm = batchnorm\n",
    "        self.first_layer_norm = first_layer_norm\n",
    "\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features))\n",
    "        weights = {\n",
    "            \"normal\": nn.init.normal_,\n",
    "            \"xavier\": nn.init.xavier_normal_,\n",
    "            \"xavier_uniform\": nn.init.xavier_uniform_,\n",
    "            \"kaiming\": nn.init.kaiming_normal_,\n",
    "            \"kaiming_uniform\": nn.init.kaiming_uniform_,\n",
    "        }\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.scaleInputs = nn.BatchNorm2d(channels)\n",
    "        self.dropout_l = nn.Dropout(self.dropout_p)\n",
    "\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.channels, 128, 3, bias=bias),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.AvgPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, bias=bias),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, bias=bias),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, bias=bias),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 64, 2, bias=bias),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, 2, bias=bias),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        in_features_fc, last_conv_out_feature = self.conv_params()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout1d(self.dropout_p),\n",
    "            nn.Linear(last_conv_out_feature * in_features_fc * in_features_fc, 300, bias=bias),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(self.dropout_p),\n",
    "            nn.Linear(300, last_hidden_neurons, bias=bias)\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(last_hidden_neurons)\n",
    "\n",
    "        self.output = nn.Linear(last_hidden_neurons, outneurons, bias=bias)\n",
    "\n",
    "\n",
    "        if weight_init:\n",
    "            self.__weight_init(weights[weight_init], bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self._train(x)\n",
    "        if self.batchnorm: x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _train(self, x):\n",
    "\n",
    "        if self.first_layer_norm: x = self.scaleInputs(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def output_last_layer(self, x):\n",
    "\n",
    "        x = self._train(x)\n",
    "        out = x.clone().detach()\n",
    "        if self.batchnorm: x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return out, x\n",
    "\n",
    "\n",
    "    def _sum_weights(self):\n",
    "\n",
    "        total_weights = 0\n",
    "        for _, p in self.named_parameters():\n",
    "            total_weights += p.sum()\n",
    "\n",
    "        return total_weights.item()\n",
    "\n",
    "    def _sum_abs_weights(self):\n",
    "\n",
    "        total_weights = 0\n",
    "        for _, p in self.named_parameters():\n",
    "            total_weights += p.abs().sum()\n",
    "\n",
    "        return total_weights.item()\n",
    "\n",
    "    def _l1_regularization(self, alpha=1e-3):\n",
    "\n",
    "        total_weights = 0\n",
    "        for _, p in self.named_parameters():\n",
    "            total_weights += p.abs().sum()\n",
    "\n",
    "        return alpha * total_weights\n",
    "\n",
    "    def _l2_regularization(self, lambd=1e-3):\n",
    "\n",
    "        total_weights = 0\n",
    "        for _, p in self.named_parameters():\n",
    "            total_weights += p.pow(2).sum()\n",
    "\n",
    "        return lambd * total_weights\n",
    "\n",
    "    def _elastic_regularization(self, lambd=1e-3, alpha=1e-3):\n",
    "        return self._l2_regularization(lambd) + self._l1_regularization(alpha)\n",
    "    \n",
    "    \n",
    "    def __weight_init(self, fn, bias):\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if (\n",
    "                isinstance(m, nn.Linear)\n",
    "                or isinstance(m, nn.Conv2d)\n",
    "                or isinstance(m, nn.Conv1d)\n",
    "               ):\n",
    "                fn(m.weight)\n",
    "\n",
    "                if bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            if isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    \n",
    "    def _calc1(self, h_w, layer):\n",
    "        return (h_w + (2 * layer.padding[0]) - (1 * (layer.kernel_size[0] - 1)) - 1)// layer.stride[0] + 1\n",
    "    \n",
    "    def _calc2(self, h_w, layer):\n",
    "        return (h_w + (2 * layer.padding) - (1 * (layer.kernel_size - 1)) - 1)// layer.stride + 1\n",
    "\n",
    "    def conv_params(self):\n",
    "\n",
    "        h_w = self.img_dim\n",
    "        last_conv_out_feature = 0\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                last_conv_out_feature = m.out_channels\n",
    "                h_w = self._calc1(h_w, m)\n",
    "            if isinstance(m, nn.MaxPool2d) or isinstance(m, nn.AvgPool2d):\n",
    "                h_w = self._calc2(h_w, m)\n",
    "\n",
    "        return h_w, last_conv_out_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add9406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FashionMNIST_CNN()\n",
    "\n",
    "model.conv_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "760aadb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 5, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv(torch.zeros((2, 1, 28, 28))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "007e6a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.zeros((2, 1, 28, 28))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c0d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f3384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2eef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
