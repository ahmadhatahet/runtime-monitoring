{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4eda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "base = Path().cwd()\n",
    "\n",
    "# switch to home directory to import helper scripts\n",
    "if str(base).split('/')[-1] != 'runtime-monitoring':\n",
    "    DATASET = str(base).split('/')[4]\n",
    "    os.chdir('../../..')\n",
    "    base = Path().cwd()\n",
    "\n",
    "print(DATASET)\n",
    "print(base)\n",
    "\n",
    "PREFIX = 'Regularization'\n",
    "FILENAME_POSTFIX = f\"{DATASET}_{PREFIX}\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.samplers import CmaEsSampler, RandomSampler, TPESampler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utils import *\n",
    "from utilities.pathManager import fetchPaths\n",
    "from Cifar10.trainingModels.Cifar10_CNN import Cifar10_CNN\n",
    "\n",
    "model_ = Cifar10_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89574d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = fetchPaths(base, DATASET)\n",
    "\n",
    "path = paths[DATASET.lower()]\n",
    "path_dataset = paths['dataset']\n",
    "path_trainingModels = paths['trainingModels']\n",
    "path_trainingModels_regularization = paths['trainingModels_regularization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2922769",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_labels(DATASET)\n",
    "\n",
    "train_full = get_dataset(DATASET, path_dataset, train=True)\n",
    "test_data = get_dataset(DATASET, path_dataset, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d717c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = int( len(train_full) * 0.05 )\n",
    "train_split = int( len(train_full) * 0.2 )\n",
    "\n",
    "train_data, _ = split_data(train_full, [train_split, len(train_full) - train_split], SEED)\n",
    "val_data, _ = split_data(train_full, [val_split, len(train_full) - val_split], SEED)\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16735ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # batchnorm\n",
    "    batchnorm = trial.suggest_int(\"batchnorm\", 0, 1)\n",
    "    \n",
    "    # dropout\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3, step=0.1)\n",
    "    \n",
    "    # model\n",
    "    model = model_(batchnorm=batchnorm, dropout=dropout)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(trial):\n",
    "    batchsize = trial.suggest_categorical(\"batchsize\", [32, 64, 128, 256])\n",
    "    \n",
    "    train_dataloader = get_dataLoader(train_data, batchsize, True)\n",
    "    val_dataloader = get_dataLoader(val_data, batchsize, False)\n",
    "\n",
    "    return train_dataloader, val_dataloader, batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader, batchsize = get_dataset(trial)\n",
    "    \n",
    "    # regularization\n",
    "    l2_ = trial.suggest_float(\"L2\", 0, 1e-2)\n",
    "    l1_ = trial.suggest_float(\"L1\", 0, 1e-2)\n",
    "\n",
    "    \n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            # regularization\n",
    "            l2_loss = model._l2_regularization(l2_)\n",
    "            l1_loss = model._l1_regularization(l1_)\n",
    "            \n",
    "            # calc loss\n",
    "            loss = F.cross_entropy(output, target) + l1_loss + l2_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                \n",
    "                \n",
    "                loss = F.cross_entropy(output, target)\n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                # Get the index of the max log-probability.\n",
    "                correct += sum(target.to(DEVICE) == output.argmax(dim=1))\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3af09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=SEED) # Default\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0], target_name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea83cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studys = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "df_studys.to_csv(base + f'/optunaResultsRegularization_{type(sampler).__name__}.csv' ,index=False)\n",
    "df_studys = df_studys.set_index('number')\n",
    "\n",
    "df_studys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e736f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = RandomSampler(seed=SEED)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da409cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0], target_name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36158216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studys = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "df_studys.to_csv(base + f'/optunaResultsRegularization_{type(sampler).__name__}.csv' ,index=False)\n",
    "df_studys = df_studys.set_index('number')\n",
    "\n",
    "df_studys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0ade6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = CmaEsSampler(seed=SEED)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed95409",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0], target_name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studys = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "df_studys.to_csv(base + f'/optunaResultsRegularization_{type(sampler).__name__}.csv' ,index=False)\n",
    "df_studys = df_studys.set_index('number')\n",
    "\n",
    "df_studys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a2bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc665a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
