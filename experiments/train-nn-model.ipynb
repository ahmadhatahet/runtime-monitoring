{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST, FashionMNIST, GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'GTSRB'\n",
    "SEED = 42\n",
    "CUDA = 0\n",
    "GPU_NAME = f'cuda:{CUDA}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path().cwd()\n",
    "\n",
    "if base.name != 'runtime-monitoring':\n",
    "    os.chdir('../')\n",
    "    base = Path().cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLmxFGnxg6ZG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from fastprogress import progress_bar, master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utils import *\n",
    "from utilities.pathManager import fetchPaths\n",
    "from utilities.scaleFunctions import *\n",
    "from utilities.pcaFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = fetchPaths(base, DATASET, '', False)\n",
    "path_data = paths['data']\n",
    "\n",
    "configs = load_json(paths['configuration'])\n",
    "config = configs['configuration']\n",
    "model_setup = configs['model_setup']\n",
    "model_config = configs['model_config']\n",
    "optim_name = list(config['optimizer'].keys())[0]\n",
    "optim_args = config['optimizer'][optim_name]\n",
    "scheduler_name = list(config['scheduler'].keys())[0]\n",
    "scheduler_args = config['scheduler'][scheduler_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7eERD3yVH2H"
   },
   "source": [
    "# GPU Device & Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CS9DVaKDi_2C"
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jRXv8RAhzqa",
    "outputId": "d8ccff46-cebe-4890-ab1c-5b498a395e64"
   },
   "outputs": [],
   "source": [
    "device = get_device(GPU_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers\n",
    "from models.transform import transform\n",
    "tf_train = transform[DATASET.lower()]['train']\n",
    "tf_test = transform[DATASET.lower()]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnist_model import MNIST_Model\n",
    "from models.fashionmnist_model import FashionMNIST_CNN\n",
    "from models.gtsrb_model import GTSRB_CNN\n",
    "\n",
    "models = {\n",
    "    'mnist': MNIST_Model,\n",
    "    'fashionmnist': FashionMNIST_CNN,\n",
    "    'gtsrb': GTSRB_CNN\n",
    "}\n",
    "\n",
    "model_ = models[DATASET.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhl = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7eERD3yVH2H"
   },
   "source": [
    "# Load / Split / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_labels(DATASET)\n",
    "\n",
    "train_data = get_dataset(DATASET, path_data, train=True, transform=tf_train)\n",
    "test_data = get_dataset(DATASET, path_data, train=False, transform=tf_test)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94CFn70JlO-P"
   },
   "outputs": [],
   "source": [
    "trainloader = get_dataLoader(train_data, model_config['batch_size'], True)\n",
    "testloader = get_dataLoader(test_data, model_config['batch_size'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_denormalize = T.Normalize(\n",
    "    mean=[-m / s for m, s in zip(tf_train.transforms[-1].mean, tf_train.transforms[-1].std)],\n",
    "    std=[1/s for s in tf_train.transforms[-1].std]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_images_loader(trainloader, feature_names=feature_names, transform=tf_denormalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setup['last_hidden_neurons'] = lhl\n",
    "\n",
    "model = model_(**model_setup).to(device)\n",
    "model = torch.compile(model)\n",
    "nn.DataParallel(model, device_ids=[CUDA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = getattr(torch.optim, optim_name)(model.parameters(), lr=model_config['lr'], **optim_args)\n",
    "scheduler = getattr(torch.optim.lr_scheduler, scheduler_name)(optimizer, **scheduler_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 1 epoch for debuging\n",
    "# model_config['epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training testing attributes\n",
    "kwargs = {\n",
    "    'model': model,\n",
    "    'loss_function': loss_function,\n",
    "    'optimizer': optimizer,\n",
    "    'lr_scheduler': scheduler,\n",
    "    'device': device,\n",
    "    'model_path': None, # to save the model pass a valid path\n",
    "    'trainloader': trainloader,\n",
    "    'testloader': testloader,\n",
    "    'config': model_config\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "(train_losses, train_accs,\n",
    "test_losses, test_accs,\n",
    "train_loss, train_acc,\n",
    "test_loss, test_acc,\n",
    "confusion_matrix_train,\n",
    "confusion_matrix_test,\n",
    "model_path) = run_training_testing(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model and save LHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_path is not None:\n",
    "    # load best model\n",
    "    load_checkpoint(model, model_path)\n",
    "\n",
    "    # normalize and save matrix\n",
    "    confusion_matrix_test_norm = normalize_confusion_matrix(confusion_matrix_test)\n",
    "    save_confusion_matrix(confusion_matrix_test_norm, path_saved_model, model_name, 'test')\n",
    "\n",
    "    # export last hidden layer data\n",
    "    export_last_hidden_layer(trainloader, model, device, lhl, None, path_lhl_raw, model_name, 'raw_train')\n",
    "    export_last_hidden_layer(testloader, model, device, lhl, None, path_lhl_raw, model_name, 'raw_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_path is not None:\n",
    "    # model postfix\n",
    "    postfix = f\"{optim_name}-{model_config['batch_size']}-{lhl}\"\n",
    "    model_name = f\"{DATASET}_{postfix}\"\n",
    "\n",
    "    # get paths\n",
    "    paths_ = fetchPaths(base, DATASET, postfix)\n",
    "    p_lhl = paths_['lhl']\n",
    "    p_lhl_raw = paths_['lhl_raw']\n",
    "    p_lhl_pca = paths_['lhl_pca']\n",
    "\n",
    "    # load data\n",
    "    train = pd.read_csv(p_lhl_raw / f'{model_name}_raw_train.csv')\n",
    "    test = pd.read_csv(p_lhl_raw / f'{model_name}_raw_test.csv')\n",
    "\n",
    "    # fit scaler and pca\n",
    "    # using only true instances from train\n",
    "    true = train.loc[train['true'] == True]\n",
    "    scaler_ = fitStandardScalerSingle(true, lhl)\n",
    "    pca_ = fitPCASingle(true, scaler=scaler_, numNeurons=lhl)\n",
    "\n",
    "    # save objects\n",
    "    save_pickle(p_lhl / 'scaler.pkl', scaler_)\n",
    "    save_pickle(p_lhl / 'pca.pkl', pca_)\n",
    "\n",
    "    # transform and save data\n",
    "    ## train\n",
    "    applyPCASingle(p_lhl_pca, train, scaler=scaler_, numNeurons=lhl).to_csv(p_lhl_pca / f'{model_name}_pca_train.csv', index=False)\n",
    "\n",
    "    ## test\n",
    "    applyPCASingle(p_lhl_pca, test, scaler=scaler_, numNeurons=lhl).to_csv(p_lhl_pca / f'{model_name}_pca_test.csv', index=False)\n",
    "\n",
    "    # save selected neurons\n",
    "    gte_mean, top_third = neuronsLoadingsSingle(pca_, numNeurons=lhl, var_thld=0.9, loadings_thld=0.2)\n",
    "    save_json(p_lhl / 'neurons_gte_mean.json', gte_mean)\n",
    "    save_json(p_lhl / 'neurons_top_third.json', top_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mcDeYOA8d1wL"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b89e4666a1b1f5f90ada5928a1b04d9ad859bf674b23c56e0417352230a6456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
